# ğŸ“Š M-GPT æ•°æ®å¤„ç†è¯¦ç»†æµç¨‹è§£æ

## ğŸ¯ è®­ç»ƒç›®æ ‡ä¸æŸå¤±å‡½æ•°è¯¦è§£

### 1. æŸå¤±å‡½æ•°å…¬å¼è§£æ

```
loss = Î£_m loss_fct(g_i,t^(m), true_label)
```

**å«ä¹‰**ï¼š
- `g_i,t^(m)`: ç¬¬ `m` é˜¶ï¼ˆå±‚ï¼‰å¯¹ä½ç½® `i` çš„ç‰©å“ `t` çš„é¢„æµ‹å¾—åˆ†
- `m âˆˆ [1, item_level]`: éå†æ‰€æœ‰é˜¶ï¼ˆé»˜è®¤ item_level=3ï¼‰
- `loss_fct`: CrossEntropyLossï¼Œå¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±

**ä»£ç å®ç°**ï¼ˆç¬¬296-299è¡Œï¼‰ï¼š
```python
for i in range(self.item_level):  # m = 1, 2, 3
    logits = torch.matmul(multi_output[i], test_item_emb.transpose(0, 1))
    # logits: [B, mask_len, item_num] - å¯¹æ‰€æœ‰ç‰©å“çš„é¢„æµ‹å¾—åˆ†
    # pos_items: [B, mask_len] - çœŸå®æ ‡ç­¾ï¼ˆè¢«æ©ç çš„ç‰©å“IDï¼‰
    
    loss = loss + torch.sum(
        loss_fct(logits.view(-1, item_num), pos_items.view(-1)) * targets
    ) / torch.sum(targets)
```

**æŸå¤±è®¡ç®—æ­¥éª¤**ï¼š
1. **å¤šé˜¶é¢„æµ‹**ï¼šå¯¹æ¯ä¸ªè¢«æ©ç ä½ç½®ï¼Œè®¡ç®— 1é˜¶ã€2é˜¶ã€3é˜¶çš„é¢„æµ‹
2. **æ¦‚ç‡åˆ†å¸ƒ**ï¼š`logits` æ˜¯ `[B, mask_len, item_num]`ï¼Œè¡¨ç¤ºæ¯ä¸ªä½ç½®å¯¹æ‰€æœ‰ç‰©å“çš„å¾—åˆ†
3. **äº¤å‰ç†µ**ï¼šçœŸå®æ ‡ç­¾ `pos_items` vs é¢„æµ‹åˆ†å¸ƒ `logits`
4. **åŠ æƒæ±‚å’Œ**ï¼š`targets` ç”¨äºå¿½ç•¥ paddingï¼ˆå€¼ä¸º0çš„ä½ç½®ï¼‰

---

## ğŸ“ˆ å®Œæ•´æ•°æ®æµè¯¦ç»†è§£æ

### é˜¶æ®µ 0ï¸âƒ£ï¼šè¾“å…¥æ•°æ®æ ¼å¼

**åŸå§‹åºåˆ—**ï¼ˆæ¥è‡ª RecBole çš„ SequentialDatasetï¼‰ï¼š
```
item_seq:    [i1, i2, i3, i4, i5, 0, 0, ...]  # é•¿åº¦ 200ï¼Œä¸è¶³ç”¨ 0 padding
type_seq:    [c,  c,  a,  c,  b,  0, 0, ...]  # c=click, a=cart, b=buy
last_buy:    i5  # æœ€åä¸€ä¸ªçœŸå®ç‰©å“ï¼ˆè´­ä¹°ç‰©å“ï¼‰
```

**å½¢çŠ¶**ï¼š
- `item_seq`: `[B, 200]` - B æ˜¯ batch size
- `type_seq`: `[B, 200]` 
- `last_buy`: `[B]`

---

### é˜¶æ®µ 1ï¸âƒ£ï¼šæ·»åŠ æœ€åè´­ä¹°ç‰©å“ï¼ˆç¬¬142-146è¡Œï¼‰

**ç›®çš„**ï¼šç¡®ä¿æœ€åä½ç½®æ˜¯çœŸå®çš„è´­ä¹°ç‰©å“ï¼ˆç”¨äºé¢„æµ‹ï¼‰

```python
# è®¡ç®—æœ‰æ•ˆåºåˆ—é•¿åº¦
n_objs = (torch.count_nonzero(item_seq, dim=1) + 1).tolist()
# ä¾‹å¦‚ï¼š[5, 3, 7, ...] - æ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆé•¿åº¦

# åœ¨åºåˆ—æœ«å°¾æ·»åŠ  last_buy
for batch_id in range(batch_size):
    n_obj = n_objs[batch_id]  # ä¾‹å¦‚ï¼š5
    item_seq[batch_id][n_obj - 1] = last_buy[batch_id]  # ä½ç½®4ï¼ˆç¬¬5ä¸ªï¼‰
    type_seq[batch_id][n_obj - 1] = self.buy_type      # è®¾ä¸ºè´­ä¹°è¡Œä¸º
```

**ç»“æœ**ï¼š
```
item_seq:    [i1, i2, i3, i4, i5, 0, 0, ...]  # i5 å·²åœ¨æœ€åï¼ˆæˆ–æ›¿æ¢åŸi5ï¼‰
type_seq:    [c,  c,  a,  c,  b,  0, 0, ...]  # æœ€åæ˜¯ buy è¡Œä¸º
æœ‰æ•ˆé•¿åº¦:    5
```

---

### é˜¶æ®µ 2ï¸âƒ£ï¼šéšæœºæ©ç ç­–ç•¥ï¼ˆç¬¬157-173è¡Œï¼‰

**æ©ç è§„åˆ™**ï¼ˆé‡è¦ï¼ï¼‰ï¼š
1. **æœ€åä¸€ä¸ªä½ç½®å¿…æ©ç **ï¼ˆç¬¬162-167è¡Œï¼‰
2. **å…¶ä»–ä½ç½®éšæœºæ©ç **ï¼Œæ¦‚ç‡ = `mask_ratio = 0.2`ï¼ˆç¬¬168-173è¡Œï¼‰
3. **æ©ç ä½ç½®çš„è¡Œä¸ºç±»å‹è®¾ä¸º 0**

**ä»£ç æµç¨‹**ï¼š
```python
for instance_idx, instance in enumerate(sequence_instances):
    masked_sequence = instance.copy()  # å¤åˆ¶åŸå§‹åºåˆ—
    pos_item = []      # å­˜å‚¨è¢«æ©ç çš„çœŸå®ç‰©å“
    index_ids = []     # å­˜å‚¨è¢«æ©ç çš„ä½ç½®ç´¢å¼•
    
    for index_id, item in enumerate(instance):
        # è§„åˆ™1: æœ€åä¸€ä¸ªä½ç½®å¿…å®šæ©ç 
        if index_id == n_objs[instance_idx] - 1:
            pos_item.append(item)              # ä¿å­˜çœŸå®ç‰©å“
            masked_sequence[index_id] = self.mask_token  # æ›¿æ¢ä¸º [MASK]
            type_instances[instance_idx][index_id] = 0    # è¡Œä¸ºè®¾ä¸º0
            index_ids.append(index_id)         # è®°å½•ä½ç½®
            break  # æœ€åä¸€ä¸ªå¤„ç†å®Œå°±é€€å‡º
        
        # è§„åˆ™2: å…¶ä»–ä½ç½®éšæœºæ©ç 
        prob = random.random()
        if prob < self.mask_ratio:  # mask_ratio = 0.2
            pos_item.append(item)
            masked_sequence[index_id] = self.mask_token
            type_instances[instance_idx][index_id] = 0
            index_ids.append(index_id)
```

**ç¤ºä¾‹**ï¼ˆå‡è®¾éšæœºé€‰æ‹©ä½ç½®2è¢«æ©ç ï¼‰ï¼š
```
åŸå§‹åºåˆ—:
item_seq:    [i1, i2, i3, i4, i5]
type_seq:    [c,  c,  a,  c,  b]
æœ‰æ•ˆé•¿åº¦:    5

æ©ç è¿‡ç¨‹:
ä½ç½®0 (i1):  éšæœºæ•° 0.85 > 0.2 â†’ ä¸æ©ç 
ä½ç½®1 (i2):  éšæœºæ•° 0.15 < 0.2 â†’ æ©ç ï¼ âœ“
ä½ç½®2 (i3):  éšæœºæ•° 0.92 > 0.2 â†’ ä¸æ©ç 
ä½ç½®3 (i4):  éšæœºæ•° 0.78 > 0.2 â†’ ä¸æ©ç 
ä½ç½®4 (i5):  æœ€åä½ç½® â†’ å¿…å®šæ©ç ï¼ âœ“

æ©ç å:
masked_seq:  [i1, [M], i3, i4, [M]]  # [M] = mask_token (é€šå¸¸æ˜¯ n_items+1)
type_seq:    [c,  0,   a,  c,  0]    # æ©ç ä½ç½®è¡Œä¸ºè®¾ä¸º0
pos_items:   [i2, i5]                # çœŸå®æ ‡ç­¾
masked_index:[1,  4]                 # è¢«æ©ç çš„ä½ç½®
```

**è¾“å‡ºå½¢çŠ¶**ï¼š
- `masked_item_sequence`: `[B, max_len+1]` - æ©ç åçš„åºåˆ—
- `pos_items`: `[B, mask_item_length]` - çœŸå®ç‰©å“ï¼ˆå¡«å……åˆ°å›ºå®šé•¿åº¦ï¼‰
- `masked_index`: `[B, mask_item_length]` - æ©ç ä½ç½®ç´¢å¼•
- `type_instances`: `[B, max_len+1]` - æ©ç åçš„è¡Œä¸ºåºåˆ—

---

### é˜¶æ®µ 3ï¸âƒ£ï¼šå›¾å·ç§¯ï¼ˆæ­¥éª¤ 1-3ï¼‰

**è¾“å…¥**ï¼š
```
masked_item_seq:  [i1, [M], i3, i4, [M]]  # [B, N+1]
type_seq:         [c,  0,   a,  c,  0]    # [B, N+1]
```

**å¤„ç†**ï¼š
```python
# 1. ç‰©å“åµŒå…¥
item_emb = self.item_embedding(masked_item_seq)  # [B, N+1, H]

# 2. è¡Œä¸ºåµŒå…¥
type_emb = self.type_embedding(type_seq)        # [B, N+1, H]

# 3. æ„å»ºé‚»æ¥çŸ©é˜µï¼ˆäº¤äº’çº§ä¾èµ–ï¼‰
# E[i,j] = item_emb[i] Â· item_emb[j]
# B[i,j] = type_emb[i] Â· type_emb[j]
# A = E âŠ™ B

# 4. å›¾å·ç§¯ï¼ˆå¤šé˜¶ï¼‰
H = self.MLGCN_layer(item_emb, type_emb, adj_matrix)
# è¾“å‡º: H^(1), H^(2), H^(3) - 1é˜¶ã€2é˜¶ã€3é˜¶è¡¨ç¤º
```

**è¾“å‡º**ï¼š
```
H^(1):  [B, N+1, H]  # 1é˜¶å›¾å·ç§¯ï¼ˆç›´æ¥é‚»å±…ï¼‰
H^(2):  [B, N+1, H]  # 2é˜¶å›¾å·ç§¯ï¼ˆ2è·³é‚»å±…ï¼‰
H^(3):  [B, N+1, H]  # 3é˜¶å›¾å·ç§¯ï¼ˆ3è·³é‚»å±…ï¼‰
```

---

### é˜¶æ®µ 4ï¸âƒ£ï¼šå¤šé¢ Transformerï¼ˆæ­¥éª¤ 4-9ï¼‰

**è¾“å…¥**ï¼š`H^(l)` - å›¾å·ç§¯çš„è¾“å‡º

**æ­¥éª¤5-6ï¼šå…¨å±€æ¨¡å¼**ï¼š
```python
# æ·»åŠ ä½ç½®ç¼–ç 
H_with_pos = H + position_embedding

# çº¿æ€§è‡ªæ³¨æ„åŠ›ï¼ˆå…¨å±€ï¼‰
H_Lin = LinSA(H_with_pos)  # [B, N+1, H]
```

**æ­¥éª¤7ï¼šå¤šç²’åº¦æ¨¡å¼**ï¼š
```python
# å¤šç²’åº¦å¤šå¤´è‡ªæ³¨æ„åŠ›
S_t1 = MGMHSA(H_with_pos, scale=4)   # çŸ­æœŸï¼ˆæœ€è¿‘4ä¸ªï¼‰
S_t2 = MGMHSA(H_with_pos, scale=20)  # ä¸­æœŸï¼ˆæœ€è¿‘20ä¸ªï¼‰
```

**æ­¥éª¤8-9ï¼šèåˆä¸FFN**ï¼š
```python
# èåˆ
H_fused = Concat([H_Lin, S_t1, S_t2]) @ W_d  # [B, N+1, H]

# å‰é¦ˆç½‘ç»œ
H_out = LayerNorm(FFN(H_fused) + H_fused)  # [B, N+1, H]
```

**è¾“å‡º**ï¼ˆæ¯ä¸ªé˜¶ï¼‰ï¼š
```
seq_output[0]:  [B, N+1, H]  # 1é˜¶çš„æœ€ç»ˆè¡¨ç¤º
seq_output[1]:  [B, N+1, H]  # 2é˜¶çš„æœ€ç»ˆè¡¨ç¤º
seq_output[2]:  [B, N+1, H]  # 3é˜¶çš„æœ€ç»ˆè¡¨ç¤º
```

---

### é˜¶æ®µ 5ï¸âƒ£ï¼šMaxPooling é¢„æµ‹ï¼ˆæ­¥éª¤ 10-17ï¼‰

#### æ­¥éª¤1ï¼šæ„å»º Multi-hot æ˜ å°„ï¼ˆç¬¬280è¡Œï¼‰

**ç›®çš„**ï¼šä»å®Œæ•´åºåˆ—è¡¨ç¤ºä¸­æå–è¢«æ©ç ä½ç½®çš„è¡¨ç¤º

```python
pred_index_map = self.multi_hot_embed(masked_index, masked_item_seq.size(-1))
# masked_index: [B, mask_len] = [[1, 4], [2, 5], ...]
# è¾“å‡º: [B, mask_len, max_len+1]
```

**Multi-hot ç¤ºä¾‹**ï¼š
```python
masked_index = [[1, 4], [0, 2]]  # 2ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæœ‰2ä¸ªæ©ç ä½ç½®
max_len = 5

pred_index_map = [
    # æ ·æœ¬1
    [[0, 1, 0, 0, 0],   # ä½ç½®1çš„ one-hot
     [0, 0, 0, 0, 1]],  # ä½ç½®4çš„ one-hot
    # æ ·æœ¬2
    [[1, 0, 0, 0, 0],   # ä½ç½®0çš„ one-hot
     [0, 0, 1, 0, 0]]   # ä½ç½®2çš„ one-hot
]
```

#### æ­¥éª¤2ï¼šæå–è¢«æ©ç ä½ç½®çš„è¡¨ç¤ºï¼ˆç¬¬288è¡Œï¼‰

```python
for j in range(self.item_level):  # j = 0, 1, 2 (å¯¹åº”1,2,3é˜¶)
    # çŸ©é˜µä¹˜æ³•ï¼šä»å®Œæ•´åºåˆ—ä¸­æå–æ©ç ä½ç½®çš„è¡¨ç¤º
    output_j = torch.bmm(pred_index_map, seq_output[j])
    # pred_index_map: [B, mask_len, max_len+1]
    # seq_output[j]:  [B, max_len+1, H]
    # ç»“æœ: [B, mask_len, H]
    multi_output.append(output_j)
```

**ç»“æœ**ï¼š
```
multi_output[0]:  [B, mask_len, H]  # 1é˜¶çš„æ©ç ä½ç½®è¡¨ç¤º
multi_output[1]:  [B, mask_len, H]  # 2é˜¶çš„æ©ç ä½ç½®è¡¨ç¤º
multi_output[2]:  [B, mask_len, H]  # 3é˜¶çš„æ©ç ä½ç½®è¡¨ç¤º
```

#### æ­¥éª¤3ï¼šè®¡ç®—é¢„æµ‹å¾—åˆ†ï¼ˆç¬¬297è¡Œï¼‰

```python
for i in range(self.item_level):
    logits = torch.matmul(multi_output[i], test_item_emb.transpose(0, 1))
    # multi_output[i]: [B, mask_len, H]
    # test_item_emb:   [item_num, H]
    # ç»“æœ: [B, mask_len, item_num]
```

**å«ä¹‰**ï¼š
- å¯¹æ¯ä¸ªè¢«æ©ç ä½ç½®ï¼Œè®¡ç®—å®ƒä¸**æ‰€æœ‰ç‰©å“**çš„ç›¸ä¼¼åº¦
- `logits[b, m, v]` = æ ·æœ¬ `b` çš„æ©ç ä½ç½® `m` å¯¹ç‰©å“ `v` çš„é¢„æµ‹å¾—åˆ†

**ç¤ºä¾‹**ï¼š
```
logits[0, 0, :] = [0.1, 0.9, 0.3, 0.2, ...]  # æ ·æœ¬1çš„æ©ç ä½ç½®1å¯¹æ‰€æœ‰ç‰©å“çš„å¾—åˆ†
logits[0, 1, :] = [0.2, 0.1, 0.8, 0.1, ...]  # æ ·æœ¬1çš„æ©ç ä½ç½®4å¯¹æ‰€æœ‰ç‰©å“çš„å¾—åˆ†

çœŸå®æ ‡ç­¾:
pos_items[0] = [i2, i5]  # ä½ç½®1çš„çœŸå®ç‰©å“æ˜¯i2ï¼Œä½ç½®4çš„çœŸå®ç‰©å“æ˜¯i5
```

#### æ­¥éª¤4ï¼šè®¡ç®—æŸå¤±ï¼ˆç¬¬298-299è¡Œï¼‰

```python
loss_fct = nn.CrossEntropyLoss(reduction='none')
targets = (masked_index > 0).float().view(-1)  # å¿½ç•¥paddingä½ç½®

for i in range(self.item_level):
    # æ¯ä¸ªé˜¶çš„æŸå¤±
    loss_i = loss_fct(
        logits.view(-1, item_num),  # [B*mask_len, item_num]
        pos_items.view(-1)            # [B*mask_len] - çœŸå®æ ‡ç­¾
    ) * targets
    
    loss += torch.sum(loss_i) / torch.sum(targets)
```

**æŸå¤±è®¡ç®—ç¤ºä¾‹**ï¼š
```
å‡è®¾æœ‰1ä¸ªæ ·æœ¬ï¼Œ2ä¸ªæ©ç ä½ç½®ï¼š
logits[0]:  [B=1, mask_len=2, item_num=1000]
pos_items: [i2=2, i5=5]

å¯¹ä½ç½®1ï¼ˆçœŸå®ç‰©å“i2ï¼‰ï¼š
- logits[0,0,:] = [0.1, 0.9, 0.3, ...]  # å¯¹i2çš„å¾—åˆ†æœ€é«˜
- CrossEntropy(i2) = -log(softmax(0.9)) = 0.11  # æŸå¤±è¾ƒå°

å¯¹ä½ç½®4ï¼ˆçœŸå®ç‰©å“i5ï¼‰ï¼š
- logits[0,1,:] = [0.2, 0.1, 0.8, ...]  # å¯¹i5çš„å¾—åˆ†
- CrossEntropy(i5) = -log(softmax(0.8)) = 0.22  # æŸå¤±

æ€»æŸå¤± = (0.11 + 0.22) / 2 = 0.165
```

**å¤šé˜¶æŸå¤±**ï¼š
```python
loss = loss_1é˜¶ + loss_2é˜¶ + loss_3é˜¶  # ä¸‰ä¸ªé˜¶çš„æŸå¤±ç›¸åŠ 
```

---

## ğŸ¯ å…³é”®ç†è§£ç‚¹

### 1. **ä¸ºä»€ä¹ˆè¦æ©ç ï¼Ÿ**
- **è‡ªç›‘ç£å­¦ä¹ **ï¼šé€šè¿‡é¢„æµ‹è¢«æ©ç çš„ç‰©å“ï¼Œæ¨¡å‹å­¦ä¹ åºåˆ—æ¨¡å¼
- **ç±»ä¼¼ BERT**ï¼šé€šè¿‡æ©ç è¯­è¨€æ¨¡å‹å­¦ä¹ è¯­è¨€ç†è§£

### 2. **ä¸ºä»€ä¹ˆæœ€åä½ç½®å¿…æ©ç ï¼Ÿ**
- **å…³é”®ä»»åŠ¡**ï¼šé¢„æµ‹ä¸‹ä¸€ä¸ªè´­ä¹°ç‰©å“ï¼ˆNext-Item Predictionï¼‰
- **å®é™…åº”ç”¨**ï¼šåœ¨æ¨èç³»ç»Ÿä¸­ï¼Œé¢„æµ‹ç”¨æˆ·ä¸‹ä¸€æ­¥ä¼šä¹°ä»€ä¹ˆ

### 3. **ä¸ºä»€ä¹ˆå¤šé˜¶ï¼Ÿ**
- **1é˜¶**ï¼šç›´æ¥ç›¸é‚»ç‰©å“çš„ä¾èµ–ï¼ˆi3 ä¾èµ–äº i2ï¼‰
- **2é˜¶**ï¼š2è·³ä¾èµ–ï¼ˆi4 ä¾èµ–äº i2ï¼Œé€šè¿‡ i3ï¼‰
- **3é˜¶**ï¼šæ›´æ·±å±‚çš„ä¾èµ–å…³ç³»
- **MaxPooling**ï¼šé€‰æ‹©æœ€ä½³é˜¶çš„é¢„æµ‹

### 4. **mask_item_length çš„ä½œç”¨ï¼Ÿ**
```python
self.mask_item_length = int(self.mask_ratio * self.max_seq_length)
# mask_ratio = 0.2, max_seq_length = 200
# mask_item_length = 40
```
- **å›ºå®šé•¿åº¦**ï¼šç¡®ä¿ batch ä¸­æ‰€æœ‰æ ·æœ¬çš„ `pos_items` é•¿åº¦ä¸€è‡´
- **Padding**ï¼šå¦‚æœæ©ç ä½ç½®å°‘äº40ä¸ªï¼Œç”¨0å¡«å……

---

## ğŸ“ å®Œæ•´ç¤ºä¾‹

**è¾“å…¥**ï¼š
```
item_seq:    [i1, i2, i3, i4, i5, 0, 0, ...]
type_seq:    [c,  c,  a,  c,  b,  0, 0, ...]
last_buy:    i5
```

**æ©ç å**ï¼š
```
masked_seq:  [i1, [M], i3, i4, [M], 0, 0, ...]
type_seq:    [c,  0,   a,  c,  0,   0, 0, ...]
pos_items:   [i2, i5, 0,  0, ...]  # å¡«å……åˆ°40
masked_index:[1,  4,  0,  0, ...]  # å¡«å……åˆ°40
```

**æ¨¡å‹è¾“å‡º**ï¼š
```
logits:      [B, 2, item_num]  # 2ä¸ªæ©ç ä½ç½® Ã— æ‰€æœ‰ç‰©å“
# å¯¹ä½ç½®1: é¢„æµ‹ i2ï¼ˆçœŸå®æ ‡ç­¾ï¼‰
# å¯¹ä½ç½®4: é¢„æµ‹ i5ï¼ˆçœŸå®æ ‡ç­¾ï¼‰
```

**æŸå¤±**ï¼š
```
loss = CrossEntropy(pred_i2, true_i2) + CrossEntropy(pred_i5, true_i5)
```

---

## âœ… æ€»ç»“

1. **æ©ç ç­–ç•¥**ï¼š20%éšæœº + æœ€åä½ç½®å¿…æ©ç 
2. **å¤šé˜¶é¢„æµ‹**ï¼š1é˜¶ã€2é˜¶ã€3é˜¶å›¾å·ç§¯ â†’ å¤šç²’åº¦ Transformer â†’ å„è‡ªé¢„æµ‹
3. **æŸå¤±è®¡ç®—**ï¼šæ¯ä¸ªé˜¶åˆ†åˆ«è®¡ç®— CrossEntropyï¼Œç„¶åæ±‚å’Œ
4. **è®­ç»ƒç›®æ ‡**ï¼šæœ€å°åŒ–æ‰€æœ‰é˜¶åœ¨æ‰€æœ‰æ©ç ä½ç½®çš„é¢„æµ‹è¯¯å·®

è¿™ä¸ªæµç¨‹ä½¿å¾— M-GPT èƒ½å¤Ÿï¼š
- âœ… å­¦ä¹ åºåˆ—æ¨¡å¼ï¼ˆé€šè¿‡æ©ç é¢„æµ‹ï¼‰
- âœ… æ•è·å¤šç²’åº¦åå¥½ï¼ˆå¤šå°ºåº¦ Transformerï¼‰
- âœ… åˆ©ç”¨å¤šé˜¶ä¾èµ–ï¼ˆå›¾å·ç§¯ï¼‰
- âœ… è‡ªé€‚åº”é€‰æ‹©æœ€ä½³é¢„æµ‹ï¼ˆMaxPoolingï¼‰

